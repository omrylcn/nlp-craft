# ðŸ“š 29-Day LLM Paper Challenge - Complete Collection


## ðŸ“‹ Week 1: Foundation & Basics (GÃ¼n 1-7)

### **GÃ¼n 1: Large Language Models: A Survey**
- **arXiv ID:** `2402.06196`
- **Link:** https://arxiv.org/abs/2402.06196
- **Kategori:** Survey, Foundation, Comprehensive Overview
- **Neden ilk:** Genel bakÄ±ÅŸ, terminoloji, GPT/LLaMA/PaLM families
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 2: Instruction Tuning for Large Language Models: A Survey**
- **arXiv ID:** `2308.10792`
- **Link:** https://arxiv.org/abs/2308.10792
- **Kategori:** Survey, Instruction Tuning, SFT Methodology
- **Neden:** Core IT/SFT concepts, dataset construction
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 3: LIMA: Less Is More for Alignment**
- **arXiv ID:** `2305.11206`
- **Link:** https://arxiv.org/abs/2305.11206
- **Kategori:** Data Efficiency, Alignment, Quality over Quantity
- **Neden:** Superficial alignment hypothesis, 1K sample ile GPT-4 level
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 4: How Abilities in LLMs are Affected by SFT Data Composition**
- **arXiv ID:** `2310.05492`
- **Link:** https://arxiv.org/abs/2310.05492
- **Kategori:** SFT Strategy, Multi-task Learning, Data Composition
- **Neden:** Senin alanÄ±na direkt - math/code/general abilities interplay
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 5: A Closer Look at the Limitations of Instruction Tuning**
- **arXiv ID:** `2402.05119`
- **Link:** https://arxiv.org/abs/2402.05119
- **Kategori:** Critical Analysis, Limitations, SFT Critique
- **Neden:** Critical thinking - IT'nin sÄ±nÄ±rlarÄ±nÄ± anlamak
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 6: The False Promise of Imitating Proprietary LLMs**
- **arXiv ID:** `2305.15717`
- **Link:** https://arxiv.org/abs/2305.15717
- **Kategori:** Knowledge Distillation, Imitation Learning Critique
- **Neden:** Proprietary model'leri imitate etmenin pitfalls'larÄ±
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 7: A Survey on Evaluation of Large Language Models**
- **arXiv ID:** `2307.03109`
- **Link:** https://arxiv.org/abs/2307.03109
- **Kategori:** Evaluation, Benchmarking, Metrics
- **Neden:** Evaluation temeli - metrikler, benchmarks
- **Abstract Ã§ekilecek:** âœ…

---

## ðŸ“‹ Week 2: Advanced Fine-tuning & Data (GÃ¼n 8-14)

### **GÃ¼n 8: Instruction Pre-Training: Language Models are Supervised Multitask Learners**
- **arXiv ID:** `2406.14491`
- **Link:** https://arxiv.org/abs/2406.14491
- **Kategori:** Pre-training Innovation, Instruction Pre-training
- **Neden:** Yeni yaklaÅŸÄ±m - pretraining phase'de instruction tuning
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 9: Instruction-tuned Language Models are Better Knowledge Learners**
- **arXiv ID:** `2402.12847`
- **Link:** https://arxiv.org/abs/2402.12847
- **Kategori:** Knowledge Injection, Instruction Tuning Benefits
- **Neden:** IT'nin knowledge acquisition'a etkisi
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 10: Scaling Laws Revisited: Modeling the Role of Data Quality**
- **arXiv ID:** `2510.03313`
- **Link:** https://arxiv.org/abs/2510.03313
- **Kategori:** Scaling Laws, Data Quality Theory
- **Neden:** Data quality'nin scaling'e etkisi - theoretical foundation
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 11: Strategic Data Ordering: Curriculum Learning**
- **arXiv ID:** `2405.07490`
- **Link:** https://arxiv.org/abs/2405.07490
- **Kategori:** Curriculum Learning, Data Ordering
- **Neden:** Senin curriculum Ã§alÄ±ÅŸmalarÄ±na direkt - data ordering strategies
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 12: How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining**
- **arXiv ID:** `2511.18903`
- **Link:** https://arxiv.org/abs/2511.18903
- **Kategori:** Curriculum Learning, LR Scheduling, Training Dynamics
- **Neden:** Ã‡ok gÃ¼ncel (Nov 2025), LR decay + curriculum interaction
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 13: Diversity-Oriented Data Augmentation with Large Language Models**
- **arXiv ID:** `2502.11671`
- **Link:** https://arxiv.org/abs/2502.11671
- **Kategori:** Data Augmentation, Diversity, Synthetic Data
- **Neden:** LLM ile data augmentation strategies
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 14: Evaluating the Diversity and Quality of LLM Generated Content**
- **arXiv ID:** `2504.12522`
- **Link:** https://arxiv.org/abs/2504.12522
- **Kategori:** Quality Metrics, Diversity Evaluation, Generated Content
- **Neden:** Synthetic data quality assessment
- **Abstract Ã§ekilecek:** âœ…

---

## ðŸ“‹ Week 3: Knowledge & Memory (GÃ¼n 15-21)

### **GÃ¼n 15: How Do LLMs Acquire New Knowledge? (Knowledge Circuits)**
- **arXiv ID:** `2502.11196`
- **Link:** https://arxiv.org/abs/2502.11196
- **Kategori:** Knowledge Acquisition, Mechanistic Interpretability
- **Neden:** LLM'lerin knowledge acquisition mechanisms - deep dive
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 16: Memorization and Knowledge Injection in Gated LLMs**
- **arXiv ID:** `2504.21239`
- **Link:** https://arxiv.org/abs/2504.21239
- **Kategori:** Memory Systems, Knowledge Injection, Gated Architectures
- **Neden:** Gated LLM'lerde memory ve knowledge injection
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 17: Investigating Continual Pretraining in Large Language Models**
- **arXiv ID:** `2402.17400`
- **Link:** https://arxiv.org/abs/2402.17400
- **Kategori:** Continual Learning, Pretraining, Catastrophic Forgetting
- **Neden:** Continual pretraining strategies - domain adaptation
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 18: Emergent Abilities in Large Language Models: A Survey**
- **arXiv ID:** `2503.05788`
- **Link:** https://arxiv.org/abs/2503.05788
- **Kategori:** Emergent Abilities, Scaling Phenomena, Survey
- **Neden:** LLM capabilities'in emergence patterns
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 19: Context Engineering 2.0: The Context of Context Engineering**
- **arXiv ID:** `2510.26493`
- **Link:** https://arxiv.org/abs/2510.26493
- **Kategori:** Prompting, Context Engineering, Advanced Techniques
- **Neden:** Advanced prompting ve context manipulation
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 20: Efficient Large Language Models: A Survey**
- **arXiv ID:** `2312.03863`
- **Link:** https://arxiv.org/abs/2312.03863
- **Kategori:** Efficiency, Optimization, Model Compression
- **Neden:** Efficiency techniques - quantization, pruning, distillation
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 21: Training and Serving System of Foundation Models: A Comprehensive Survey**
- **arXiv ID:** `2401.02643`
- **Link:** https://arxiv.org/abs/2401.02643
- **Kategori:** Systems, Infrastructure, Training & Serving
- **Neden:** Full system architecture - training to deployment
- **Abstract Ã§ekilecek:** âœ…

---

## ðŸ“‹ Week 4: Turkish NLP & Production (GÃ¼n 22-28)

### **GÃ¼n 22: TR-MMLU: Turkish MMLU Benchmark**
- **arXiv ID:** `2501.00593`
- **Link:** https://arxiv.org/abs/2501.00593
- **Kategori:** Turkish NLP, Benchmark, Evaluation
- **Neden:** **SENÄ°N ALANIN!** Turkish LLM evaluation benchmark
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 23: Cetvel: Turkish LLM Benchmark**
- **arXiv ID:** `2508.16431`
- **Link:** https://arxiv.org/abs/2508.16431
- **Kategori:** Turkish NLP, Benchmark, Comprehensive Evaluation
- **Neden:** Ä°kinci Turkish benchmark - comprehensive evaluation suite
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 24: LLM Inference Serving: Survey of Recent Advances**
- **arXiv ID:** `2407.12391`
- **Link:** https://arxiv.org/abs/2407.12391
- **Kategori:** Inference, Serving, Production Systems
- **Neden:** Production-ready inference optimization
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 25: A Survey on Inference Engines for Large Language Models**
- **arXiv ID:** `2505.01658`
- **Link:** https://arxiv.org/abs/2505.01658
- **Kategori:** Inference Engines, Optimization, Deployment
- **Neden:** vLLM, TensorRT-LLM, etc. - inference engine comparison
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 26: Phi-4 Technical Report**
- **arXiv ID:** `2412.08905`
- **Link:** https://arxiv.org/abs/2412.08905
- **Kategori:** Model Release, Technical Report, SOTA
- **Neden:** Microsoft'un latest small model - architecture & training details
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 27: Phi-4-reasoning Technical Report**
- **arXiv ID:** `2504.21318`
- **Link:** https://arxiv.org/abs/2504.21318
- **Kategori:** Reasoning, Model Release, Technical Report
- **Neden:** Phi-4'Ã¼n reasoning-focused version
- **Abstract Ã§ekilecek:** âœ…

---

### **GÃ¼n 28: Tulu 3: Pushing Frontiers in Open Language Model Post-Training**
- **arXiv ID:** `2411.15124`
- **Link:** https://arxiv.org/abs/2411.15124
- **Kategori:** Post-training, RLHF, Open Models
- **Neden:** Allen AI'Ä±n post-training SOTA - fully open approach
- **Abstract Ã§ekilecek:** âœ…

---

## ðŸ“‹ Week 5: Bonus Day

### **GÃ¼n 29: OLMo 3 Technical Report**
- **Link:** https://allenai.org/olmo (check for latest arXiv link)
- **Alternatif:** PDF dosyasÄ± zaten mevcut: `olmo_3_technical_report-1.pdf`
- **Kategori:** Fully Open Model, Technical Report, Complete Pipeline
- **Neden:** Fully open model (data, code, training, everything) - complete transparency
- **Abstract Ã§ekilecek:** âœ… (from uploaded PDF or search)

---

## ðŸ“Š Kategori Breakdown

### SFT & Fine-tuning (6 makale)
- GÃ¼n 2, 3, 4, 5, 8, 9

### Data Quality & Diversity (5 makale)
- GÃ¼n 6, 10, 11, 12, 13, 14

### Evaluation & Benchmarking (3 makale)
- GÃ¼n 7, 22, 23

### LLM Surveys (4 makale)
- GÃ¼n 1, 2, 18, 20

### Inference & Production (2 makale)
- GÃ¼n 24, 25

### Knowledge & Memory (3 makale)
- GÃ¼n 15, 16, 17

### Context & Prompting (1 makale)
- GÃ¼n 19

### Systems & Infrastructure (1 makale)
- GÃ¼n 21

### Model Releases (4 makale)
- GÃ¼n 26, 27, 28, 29

---

## ðŸ’ª Challenge BaÅŸarÄ± Kriterleri

- [ ] 29/29 makale okundu
- [ ] Her makale iÃ§in notlar alÄ±ndÄ±
- [ ] En az 3 makaleyi kendi projene uyguladÄ±n
- [ ] Turkish financial LLM iÃ§in yeni bir ÅŸey Ã¶ÄŸrendin
- [ ] LinkedIn/Twitter'da paylaÅŸtÄ±n (opsiyonel)

---

**ðŸš€ Good luck with the challenge!**
