{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Example with LangChain and Monitoring\n",
    "\n",
    "**Two steps :** \n",
    "- create embedings and save to vector store\n",
    "- create retriever and generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from src.config import Config\n",
    "from src.document import DocumentLoader,DocumentProcessor\n",
    "from src.vector_store import VectorStore\n",
    "from src.llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "web_paths = [\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-01-10-inference-optimization/\",\n",
    "    \"https://lilianweng.github.io/posts/2022-06-09-vlm/\"\n",
    "]\n",
    "docs = DocumentLoader.load_web_documents(web_paths)\n",
    "\n",
    "\n",
    "# # Process documents\n",
    "processor = DocumentProcessor()\n",
    "\n",
    "split_docs = processor.split_documents(docs)\n",
    "# Create vector store\n",
    "vector_store = VectorStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuvis/miniconda3/envs/hf/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from src.rag import RAG\n",
    "from src.config import Config\n",
    "from src.vector_store import VectorStore\n",
    "from src.llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v1/tenants/default_tenant \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8000/api/v1/databases/default_database?tenant=default_tenant \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v1/collections?tenant=default_tenant&database=default_database \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    " # Initialize vector store\n",
    "vector_store = VectorStore()\n",
    "retriever = vector_store.get_retriever()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = LLM().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuvis/miniconda3/envs/hf/lib/python3.11/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "INFO:src.db:Database initialized successfully\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "rag = RAG(retriever,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8000/api/v1/collections/0c748cc5-3d4e-4701-84c8-d693ac54f10b/query \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:src.rag:Not enough questions for trend calculation\n",
      "INFO:src.db:Conversation 69c19c99-32b8-48fa-b428-b4552b8d91ac saved successfully\n",
      "INFO:src.rag:RAG process completed for question: What is ai agent...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('An AI agent, particularly in the context of LLM-powered autonomous agents, functions as a problem solver using a large language model (LLM) as its core controller. It can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes to improve future performance. Additionally, it utilizes memory and external tools to enhance its capabilities and access information beyond its initial training.',\n",
       " {'answer': 'An AI agent, particularly in the context of LLM-powered autonomous agents, functions as a problem solver using a large language model (LLM) as its core controller. It can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes to improve future performance. Additionally, it utilizes memory and external tools to enhance its capabilities and access information beyond its initial training.',\n",
       "  'model_used': 'gpt-4o-mini',\n",
       "  'response_time': 2.177316,\n",
       "  'relevance': 'RELEVANT',\n",
       "  'prompt_tokens': 4,\n",
       "  'completion_tokens': 80,\n",
       "  'total_tokens': 84,\n",
       "  'openai_cost': 1.6400000000000002e-05,\n",
       "  'question_trend': 0.0},\n",
       " '69c19c99-32b8-48fa-b428-b4552b8d91ac')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.run(\"What is ai agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
