
# Looking Inside LLM with Expressions

## ğŸ¯ ANA KAVRAMLAR (5 Pillar)

### 1. **Next Token Prediction** âœ… (LLM'nin Ã–zÃ¼)

*"LLM'ler sadece bir sonraki kelimeyi tahmin eden sistemlerdir"*

- **PDF BaÄŸlantÄ±sÄ±:** Sayfa 2-8 (Generation sÃ¼reci)
- **Sunum SÃ¼resi:** 8-10 dakika
- **Demo:** CanlÄ± ChatGPT kelime kelime yazmasÄ±

---

### 2. **Autoregressive Model** âœ… (LLM'nin Ã‡alÄ±ÅŸma Åekli)

*"Kendi Ã§Ä±ktÄ±sÄ±nÄ± tekrar kendine input olarak verir"*

- **PDF BaÄŸlantÄ±sÄ±:** Sayfa 3-4 (Token ekleme dÃ¶ngÃ¼sÃ¼)
- **Sunum SÃ¼resi:** 8-10 dakika  
- **Demo:** "Hikaye anlatma oyunu" canlÄ± demo

---

### 3. **Attention is All You Need** (Transformer'Ä±n Kalbi)

*"Dikkat mekanizmasÄ± her ÅŸeyin anahtarÄ± - hangi kelimelerin Ã¶nemli olduÄŸunu anlar"*

- **Analoji:** Kokteyl partisinde belirli konuÅŸmalara odaklanmak
- **PDF BaÄŸlantÄ±sÄ±:** Sayfa 14-22 (Attention mechanism detaylarÄ±)
- **Sunum deÄŸeri:** Transformer'Ä±n temel prensibi
- **Demo:** "The cat sat on the mat" attention visualization

---

### 4. **In-Context Learning** (Prompting'in Sihri)

*"Parametrelerini deÄŸiÅŸtirmeden, sadece Ã¶rnek vererek Ã¶ÄŸretebilirsiniz"*

- **GÃ¼nlÃ¼k analoji:** ArkadaÅŸÄ±nÄ±za Ã¶rnekle anlatmak gibi
- **PDF BaÄŸlantÄ±sÄ±:** Sayfa 25-28 (Prompting techniques)
- **Sunum deÄŸeri:** Few-shot learning'in gÃ¼cÃ¼
- **Demo:** Zero-shot vs Few-shot comparison

---

### 5. **Foundation Models** (Yeni BÃ¶lÃ¼m - Versatility)

*"Tek model, binlerce farklÄ± gÃ¶rev - Ã§ok amaÃ§lÄ± AI temeli"*

- **Analoji:** Ä°sviÃ§re Ã§akÄ±sÄ± gibi
- **Sunum deÄŸeri:** Versatility vurgusu
- **Ã–rnekler:**
  - AynÄ± GPT-4: Email yazer, kod yazer, Ã§evirir, analiz yapar
  - Specialized model'ler vs Foundation model karÅŸÄ±laÅŸtÄ±rmasÄ±
- **Demo:** Bir model, farklÄ± gÃ¶revler showcase

---

## ğŸ”¤ TOKENIZER BÃ–LÃœMÃœ

### 6. **Text-to-Numbers, Numbers-to-Text Magic**

*"LLM'ler sayÄ±larla Ã§alÄ±ÅŸÄ±r, ama biz kelimelerle konuÅŸuruz - tokenizer kÃ¶prÃ¼ gÃ¶revi gÃ¶rÃ¼r"*

**Ana Ä°fade:**

- **Encode:** "Merhaba" â†’ [45, 123, 789]
- **Decode:** [156, 278, 934] â†’ "dÃ¼nya"

**Analojiler:**

- **Ã‡evirmen:** Ä°nsan dili â†” Bilgisayar dili
- **Morse Kodu:** Kelimeler â†” Nokta/tire
- **ÅarkÄ± NotalarÄ±:** MÃ¼zik â†” Nota yazÄ±sÄ±

**PDF BaÄŸlantÄ±sÄ±:** Sayfa 30-34
**Kritik Nokta:** "Tokenization kalitesi = Model performansÄ±"
**Demo:** "TÃ¼rkÃ§e vs Ä°ngilizce tokenization farklÄ±lÄ±klarÄ±"
